{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c64f8a-3429-484f-a2d3-2f5e68ce5577",
   "metadata": {
    "gather": {
     "logged": 1649937622421
    }
   },
   "source": [
    "# Get the song ID's\n",
    "\n",
    "In this file, we get the song id's and do a little bit of data preprocessing by cleaning out duplicates.\n",
    "We use the Spotify API library called Spotipy to easily access the data. While manually making the GET- requests would result in more clean data and more control, this is by far the easiest way to gain access to the API.\n",
    "\n",
    "In the end, we write the ID's down to a CSV file so we don't have to get them again once we have them. This also allows us to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98086d41-3a03-4035-8421-4ea1200708b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all the necessary libraries\n",
    "from requests import HTTPError\n",
    "import spotipy as spy\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a018f463-417c-4b83-9142-7dd9d0c1aae2",
   "metadata": {
    "gather": {
     "logged": 1649937624270
    }
   },
   "outputs": [],
   "source": [
    "## The secret must be hidden so not to compromise the app\n",
    "with open('secret.txt') as s:\n",
    "    client_secret = next(s)\n",
    "s.close()\n",
    "client_id = '66b50b394b214bd399d67a70be01a80e'\n",
    "## By default use a playlist which contains roughly 10,000 songs\n",
    "user = 'Willis Orr'\n",
    "playlist_uri = 'spotify:playlist:5S8SJdl1BDc0ugpkEvFsIL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6453e976-e183-4f66-b807-4d6577554309",
   "metadata": {
    "gather": {
     "logged": 1649937626660
    }
   },
   "outputs": [],
   "source": [
    "## Set up the credentials manager\n",
    "credentials_manager = spy.oauth2.SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spy.Spotify(client_credentials_manager=credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1916d995-2737-4411-b42b-f635a869185a",
   "metadata": {
    "gather": {
     "logged": 1649938473334
    }
   },
   "outputs": [],
   "source": [
    "## Get all the song id's from the playlist. The structure is quite complex, but there's practically nothing in this point we can do.\n",
    "## Append all the ID's to a list that we'll later on use to write everything down.\n",
    "pl_t = sp.user_playlist_tracks(user, playlist_uri)\n",
    "tmp = pl_t['items']\n",
    "ids = []\n",
    "while pl_t['next']:\n",
    "    pl_t = sp.next(pl_t)\n",
    "    tmp.extend(pl_t['items'])\n",
    "    for s in tmp:\n",
    "        ids.append(s[\"track\"][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae17ef7-e9de-4bde-a7ef-9f3a328403de",
   "metadata": {
    "gather": {
     "logged": 1649868153324
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of rows: 504900\n",
      "Duplicates found, 494940 rows cleaned.\n",
      "The remaining rows:  9960\n"
     ]
    }
   ],
   "source": [
    "## Do the first step of preprocessing: delete duplicate ID's from the list by converting it to a set and then back to a list.\n",
    "i = len(ids)\n",
    "print(\"Amount of rows:\", i)\n",
    "if len(ids) != len(set(ids)):\n",
    "    ids = list(set(ids))\n",
    "    print(\"Duplicates found, {} rows cleaned.\".format(i-len(ids)))\n",
    "    print(\"The remaining rows: \", len(ids))\n",
    "else:\n",
    "    print(\"No duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc6ac16-e750-4d9f-891a-df7c656688a6",
   "metadata": {
    "gather": {
     "logged": 1649868153447
    }
   },
   "outputs": [],
   "source": [
    "## Finally, write down the ID's in the list.\n",
    "## In this part, we can also check if the given ID already is in the list so we don't end up adding it again.\n",
    "## If we would like to do this process to multiple playlists, this could come in handy.\n",
    "with open('Datasets/ids.csv', 'r') as r:\n",
    "    old_ids = []\n",
    "    reader = r.read()\n",
    "    for item in reader:\n",
    "        old_ids.append(item)\n",
    "r.close()\n",
    "with open('Datasets/ids.csv', 'w') as w:\n",
    "    writer = csv.writer(w)\n",
    "    if \"track_id\" not in old_ids:\n",
    "        writer.writerow([\"track id\"])\n",
    "    for i in range(len(ids)):\n",
    "        if ids[i] not in old_ids:\n",
    "            writer.writerow([ids[i]])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f9a0a-ea48-4316-8992-8c63d07ddce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
